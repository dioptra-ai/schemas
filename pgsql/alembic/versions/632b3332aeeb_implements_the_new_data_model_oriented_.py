"""Implements the new data model oriented for data management.

Created at: 2023-01-29 20:52:27.890252
"""

revision = '632b3332aeeb'
# To prune migrations prior to this one, set this down_revision to None
# and delete the files of the prior revisions.
down_revision = '3905631f8b02'

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from alembic import context

def upgrade():
    schema_upgrades()
    data_upgrades()

def downgrade():
    data_downgrades()
    schema_downgrades()

def schema_upgrades():
    # ### commands auto generated by Alembic - please adjust! ###
    tasktype = postgresql.ENUM('OBJECT_DETECTION', 'CLASSIFICATION', 'NER', name='tasktype', create_type=False)
    tasktype.create(op.get_bind(), checkfirst=True)

    # Groundtruths
    op.create_table('groundtruths',
    sa.Column('id', postgresql.UUID(as_uuid=True), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('organization_id', sa.String(), nullable=False),
    sa.Column('datapoint', postgresql.UUID(as_uuid=True), nullable=False),
    sa.Column('task_type', tasktype, nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['datapoint'], ['datapoints.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('groundtruths_organization_id_index', 'groundtruths', ['organization_id'], unique=False)

    # Predictions
    op.create_table('predictions',
    sa.Column('id', postgresql.UUID(as_uuid=True), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('organization_id', sa.String(), nullable=False),
    sa.Column('datapoint', postgresql.UUID(as_uuid=True), nullable=False),
    sa.Column('task_type', tasktype, nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('model_name', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['datapoint'], ['datapoints.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('datapoint', 'model_name', name='predictions_datapoint_model_name_unique')
    )
    op.create_index('predictions_organization_id_index', 'predictions', ['organization_id'], unique=False)

    # Tags
    op.create_table('tags',
    sa.Column('id', postgresql.UUID(as_uuid=True), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('organization_id', sa.String(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('value', sa.String(), nullable=False),
    sa.Column('datapoint', postgresql.UUID(as_uuid=True), nullable=False),
    sa.ForeignKeyConstraint(['datapoint'], ['datapoints.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('tags_datapoint_index', 'tags', ['datapoint'], unique=False)
    op.create_index('tags_name_index', 'tags', ['name'], unique=False)
    op.create_index('tags_organization_id_index', 'tags', ['organization_id'], unique=False)
    op.create_index('tags_value_index', 'tags', ['value'], unique=False)

    # Feature Vectors
    feature_vector_type = postgresql.ENUM('EMBEDDINGS', 'LOGITS', name='featurevectortype', create_type=False)
    feature_vector_type.create(op.get_bind(), checkfirst=True)
    op.create_table('feature_vectors',
    sa.Column('id', postgresql.UUID(as_uuid=True), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('organization_id', sa.String(), nullable=False),
    sa.Column('name', feature_vector_type, nullable=False),
    sa.Column('datapoint', postgresql.UUID(as_uuid=True), nullable=True),
    sa.Column('prediction', postgresql.UUID(as_uuid=True), nullable=True),
    sa.Column('value', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('model_name', sa.String(), nullable=True),
    sa.CheckConstraint('datapoint IS NOT NULL OR prediction IS NOT NULL', name='feature_vectors_datapoint_or_prediction_set'),
    sa.ForeignKeyConstraint(['datapoint'], ['datapoints.id'], ),
    sa.ForeignKeyConstraint(['prediction'], ['predictions.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('datapoint', 'model_name', name='feature_vectors_datapoint_model_name_unique'),
    sa.UniqueConstraint('prediction', 'model_name', name='feature_vectors_prediction_model_name_unique')
    )
    op.create_index('feature_vector_organization_id_index', 'feature_vectors', ['organization_id'], unique=False)

    # Update Datapoints
    datapointtype = postgresql.ENUM('IMAGE', 'VIDEO', 'AUDIO', 'TEXT', name='datapointtype', create_type=False)
    datapointtype.create(op.get_bind(), checkfirst=True)
    op.add_column('datapoints', sa.Column('type', datapointtype, nullable=True))
    op.add_column('datapoints', sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.drop_constraint('datapoints_organization_id_request_id_unique', 'datapoints', type_='unique')
    op.drop_index('datapoints_request_id_index', table_name='datapoints')
    op.drop_column('datapoints', 'request_id')
    # ### end Alembic commands ###

def schema_downgrades():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('datapoints', sa.Column('request_id', sa.VARCHAR(), autoincrement=False, nullable=False))
    op.create_index('datapoints_request_id_index', 'datapoints', ['request_id'], unique=False)
    op.create_unique_constraint('datapoints_organization_id_request_id_unique', 'datapoints', ['organization_id', 'request_id'])
    op.drop_column('datapoints', 'metadata')
    op.drop_column('datapoints', 'type')
    op.drop_index('feature_vector_organization_id_index', table_name='feature_vectors')
    op.drop_table('feature_vectors')
    op.drop_index('tags_value_index', table_name='tags')
    op.drop_index('tags_organization_id_index', table_name='tags')
    op.drop_index('tags_name_index', table_name='tags')
    op.drop_index('tags_datapoint_index', table_name='tags')
    op.drop_table('tags')
    op.drop_index('predictions_organization_id_index', table_name='predictions')
    op.drop_table('predictions')
    op.drop_index('groundtruths_organization_id_index', table_name='groundtruths')
    op.drop_table('groundtruths')
    # ### end Alembic commands ###

def data_upgrades():
    """Add any optional data upgrade migrations here!"""
    pass

def data_downgrades():
    """Add any optional data downgrade migrations here!"""
    pass