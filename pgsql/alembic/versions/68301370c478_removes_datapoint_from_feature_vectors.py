"""removes datapoint from feature_vectors

Created at: 2023-03-29 15:36:27.581415
"""

revision = '68301370c478'
# To prune migrations prior to this one, set this down_revision to None
# and delete the files of the prior revisions.
down_revision = '36b6177ab6be'

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from alembic import context

def upgrade():
    schema_upgrades()
    data_upgrades()

def downgrade():
    data_downgrades()
    schema_downgrades()

def schema_upgrades():
    # Remove all feature vectors that have no prediction
    op.execute("DELETE FROM feature_vectors WHERE prediction IS NULL")
    # Remove the feature_vectors_datapoint_or_prediction_set CHECK constraint
    # op.execute("ALTER TABLE feature_vectors DROP CONSTRAINT feature_vectors_datapoint_or_prediction_set")

    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('feature_vectors', 'prediction',
               existing_type=postgresql.UUID(),
               nullable=False)
    op.drop_index('feature_vector_datapoint_index', table_name='feature_vectors')
    op.drop_constraint('feature_vectors_datapoint_model_name_type_unique', 'feature_vectors', type_='unique')
    op.drop_constraint('fk_feature_vectors_datapoint_datapoints', 'feature_vectors', type_='foreignkey')
    op.drop_column('feature_vectors', 'datapoint')
    # ### end Alembic commands ###

def schema_downgrades():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('feature_vectors', sa.Column('datapoint', postgresql.UUID(), autoincrement=False, nullable=True))
    op.create_foreign_key('fk_feature_vectors_datapoint_datapoints', 'feature_vectors', 'datapoints', ['datapoint'], ['id'], ondelete='CASCADE')
    op.create_unique_constraint('feature_vectors_datapoint_model_name_type_unique', 'feature_vectors', ['datapoint', 'model_name', 'type'])
    op.create_index('feature_vector_datapoint_index', 'feature_vectors', ['datapoint'], unique=False)
    op.alter_column('feature_vectors', 'prediction',
               existing_type=postgresql.UUID(),
               nullable=True)
    # ### end Alembic commands ###
    # sa.CheckConstraint('datapoint IS NOT NULL OR prediction IS NOT NULL', name=op.f('ck_feature_vectors_`feature_vectors_datapoint_or_prediction_set`')),


def data_upgrades():
    """Add any optional data upgrade migrations here!"""
    pass

def data_downgrades():
    """Add any optional data downgrade migrations here!"""
    pass