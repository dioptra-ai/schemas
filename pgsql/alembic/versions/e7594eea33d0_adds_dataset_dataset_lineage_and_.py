"""adds dataset, dataset lineage and dataset_version committed/dirty

Created at: 2023-01-15 17:15:36.953363
"""

revision = 'e7594eea33d0'
# To prune migrations prior to this one, set this down_revision to None
# and delete the files of the prior revisions.
down_revision = 'dbb2cb27542f'

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from alembic import context

def upgrade():
    schema_upgrades()
    data_upgrades()

def downgrade():
    data_downgrades()
    schema_downgrades()

def schema_upgrades():
    # ### commands auto generated by Alembic - please adjust! ###

    op.create_table('datasets',
    sa.Column('uuid', postgresql.UUID(as_uuid=True), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('organization_id', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('created_by', sa.String(), nullable=False),
    sa.Column('display_name', sa.String(), nullable=False),
    # sa.PrimaryKeyConstraint('uuid')
    )
    op.create_index('actual_datasets_organization_id_index', 'datasets', ['organization_id'], unique=False)
    op.create_table('dataset_version_lines',
    sa.Column('parent_uuid', postgresql.UUID(as_uuid=True), nullable=False),
    sa.Column('child_uuid', postgresql.UUID(as_uuid=True), nullable=False),
    sa.ForeignKeyConstraint(['child_uuid'], ['dataset_versions.uuid'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['parent_uuid'], ['dataset_versions.uuid'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('parent_uuid', 'child_uuid')
    )
    op.drop_constraint('dataset_to_datapoint_unique', 'dataset_to_datapoints', type_='unique')
    op.add_column('dataset_versions', sa.Column('message', sa.String(), nullable=True))

    # Manually added
    op.execute('DELETE FROM dataset_versions')
    # End Manually added

    op.add_column('dataset_versions', sa.Column('dataset_uuid', postgresql.UUID(as_uuid=True), nullable=False))
    op.add_column('dataset_versions', sa.Column('dirty', sa.Boolean(), server_default='false', nullable=False))
    op.add_column('dataset_versions', sa.Column('committed', sa.Boolean(), server_default='false', nullable=False))
    op.create_unique_constraint('datasets_dataset_uuid_dirty_unique', 'dataset_versions', ['dataset_uuid', 'dirty'])
    op.create_index('datasets_dataset_uuid_index', 'dataset_versions', ['dataset_uuid'], unique=False)
    # op.drop_constraint('dataset_versions_root_parent_uuid_fkey', 'dataset_versions', type_='foreignkey')

    op.create_primary_key('pkey_datasets', 'datasets', ['uuid'])
    op.create_foreign_key(None, 'dataset_versions', 'datasets', ['dataset_uuid'], ['uuid'], ondelete='CASCADE')
    op.drop_column('dataset_versions', 'is_current')
    op.drop_column('dataset_versions', 'root_parent_uuid')
    op.drop_column('dataset_versions', 'display_name')
    # ### end Alembic commands ###

def schema_downgrades():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('dataset_versions', sa.Column('display_name', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('dataset_versions', sa.Column('root_parent_uuid', postgresql.UUID(), autoincrement=False, nullable=True))
    op.add_column('dataset_versions', sa.Column('is_current', sa.BOOLEAN(), server_default=sa.text('true'), autoincrement=False, nullable=False))
    op.drop_constraint(None, 'dataset_versions', type_='foreignkey')
    op.create_foreign_key('dataset_versions_root_parent_uuid_fkey', 'dataset_versions', 'dataset_versions', ['root_parent_uuid'], ['uuid'])
    op.drop_index('datasets_dataset_uuid_index', table_name='dataset_versions')
    op.drop_constraint('datasets_dataset_uuid_dirty_unique', 'dataset_versions', type_='unique')
    op.drop_column('dataset_versions', 'committed')
    op.drop_column('dataset_versions', 'dirty')
    op.drop_column('dataset_versions', 'dataset_uuid')
    op.drop_column('dataset_versions', 'message')
    op.create_unique_constraint('dataset_to_datapoint_unique', 'dataset_to_datapoints', ['dataset_version', 'datapoint'])
    op.drop_table('dataset_version_lines')
    op.drop_index('actual_datasets_organization_id_index', table_name='datasets')
    op.drop_table('datasets')
    # ### end Alembic commands ###

def data_upgrades():
    """Add any optional data upgrade migrations here!"""
    pass

def data_downgrades():
    """Add any optional data downgrade migrations here!"""
    pass